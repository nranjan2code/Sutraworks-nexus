# Architecture Overview

## NEXUS System Architecture

This document provides a comprehensive view of the NEXUS architecture, explaining how all components integrate into a unified system.

NEXUS offers **two architecture modes**:
1. **FlowingNEXUS (Layer-Free)** - Emergent depth, recommended for new development
2. **NEXUSCore (Layered)** - Traditional stacked layers, well-tested baseline

---

## Layer-Free Architecture (FlowingNEXUS) ğŸ†•

The layer-free architecture represents a paradigm shift where **depth emerges from input complexity** rather than being a fixed hyperparameter.

### Key Concept

Traditional neural networks: `input â†’ layerâ‚ â†’ layerâ‚‚ â†’ ... â†’ layerâ‚™ â†’ output`

FlowingNEXUS: `input â†’ f(z*, input) â†’ output` where `z* = f(z*, input)` (fixed point)

### Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          FLOWING NEXUS (LAYER-FREE)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   INPUT â”€â”€â–º UnifiedDynamics f(z, x) â”€â”€â–º ITERATE â”€â”€â–º Equilibrium z* â”€â”€â–º OUT â”‚
â”‚                    â†‘                        â”‚                               â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                                                             â”‚
â”‚   UnifiedDynamics contains:                                                 â”‚
â”‚   â€¢ Continuous SSM (state space evolution)                                  â”‚
â”‚   â€¢ Continuous Attention (global context)                                   â”‚
â”‚   â€¢ Co-evolving Memory (persistent state)                                   â”‚
â”‚   â€¢ Feed-forward transformation                                             â”‚
â”‚                                                                             â”‚
â”‚   Training uses implicit differentiation: O(1) memory backprop!             â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Usage

```python
from nexus.core import create_flowing_nexus

model = create_flowing_nexus(size="base")
result = model(x, modality="continuous")

print(f"Flow steps (emergent depth): {result['flow_steps']}")
print(f"Converged: {result['converged']}")
```

---

## Living System Layer

NEXUS operates as a **living system** that evolves continuously through experience.

### Philosophy

> *Growth is not a ladder with rungs to climb.*  
> *It is water finding its level.*  
> *The system doesn't "become" something new -*  
> *it continuously IS, shaped by all it has experienced.*

### Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           LIVING NEXUS LAYER                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  UncertaintyGate  â”‚  â”‚ LifecycleManager  â”‚  â”‚  ContinualLearner â”‚       â”‚
â”‚  â”‚                   â”‚  â”‚                   â”‚  â”‚                   â”‚       â”‚
â”‚  â”‚ Anti-hallucinationâ”‚  â”‚ Continuous        â”‚  â”‚ Learn while       â”‚       â”‚
â”‚  â”‚ Refuse when       â”‚  â”‚ evolution         â”‚  â”‚ serving           â”‚       â”‚
â”‚  â”‚ uncertain         â”‚  â”‚ (no stages)       â”‚  â”‚                   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                             â”‚
â”‚  Key Metrics (all continuous, no discrete stages):                          â”‚
â”‚  â”œâ”€â”€ experience_factor: 0â†’1 smooth curve of accumulated wisdom              â”‚
â”‚  â”œâ”€â”€ confidence_threshold: 0.95â†’0.35 (cautious when new, knows limits)     â”‚
â”‚  â”œâ”€â”€ learning_rate_mult: 2.5â†’0.1 (absorbs fast, then selective)            â”‚
â”‚  â””â”€â”€ wisdom_ratio: how often it wisely says "I don't know"                 â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Production Infrastructure Layer (v2.0)

NEXUS v2.0 includes a comprehensive production infrastructure for enterprise deployment.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       PRODUCTION INFRASTRUCTURE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Control Interfaces:                                                        â”‚
â”‚  â”œâ”€â”€ nexusctl (CLI): start/stop/pause/resume/status/logs/dashboard         â”‚
â”‚  â”œâ”€â”€ Web Dashboard: Real-time monitoring, interaction, controls             â”‚
â”‚  â””â”€â”€ REST API: /api/status, /api/interact, /api/control                    â”‚
â”‚                                                                             â”‚
â”‚  Production Components:                                                     â”‚
â”‚  â”œâ”€â”€ NEXUSTokenizer: HuggingFace transformers with NEXUS special tokens    â”‚
â”‚  â”œâ”€â”€ CheckpointManager: Atomic saves, SHA256 validation, auto-rotation     â”‚
â”‚  â”œâ”€â”€ MetricsCollector: Prometheus export, P50/P95/P99, health checks       â”‚
â”‚  â”œâ”€â”€ CircuitBreaker: 3-state pattern (CLOSED/OPEN/HALF_OPEN)               â”‚
â”‚  â”œâ”€â”€ MemoryManager: Leak detection, auto-cleanup, GC orchestration         â”‚
â”‚  â”œâ”€â”€ ResourceGovernor: CPU/RAM limits (Active: 10%, Idle: 25%)             â”‚
â”‚  â””â”€â”€ NexusDaemon: Main orchestrator integrating all components             â”‚
â”‚                                                                             â”‚
â”‚  Deployment Modes:                                                          â”‚
â”‚  â”œâ”€â”€ Development: uvicorn --reload                                          â”‚
â”‚  â”œâ”€â”€ Production: systemd service (Linux) or nexusctl (Mac/Windows)         â”‚
â”‚  â”œâ”€â”€ Edge: Raspberry Pi optimized deployment                               â”‚
â”‚  â””â”€â”€ Remote: SSH tunnel, Tailscale, ngrok support                          â”‚
â”‚                                                                             â”‚
â”‚  See: docs/architecture/production.md for complete details                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Production Features**:
- **Zero Technical Debt**: All features implemented to completion
- **Real Tokenization**: No mock implementations
- **Checkpoint Persistence**: Crash-safe atomic saves
- **Comprehensive Metrics**: Production-grade observability
- **Error Recovery**: Circuit breaker, retry, graceful degradation
- **Memory Safety**: Long-running stability with leak detection
- **Resource Governance**: Strict CPU/RAM limits
- **Multiple Control Interfaces**: CLI, Dashboard, API

---

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              NEXUS CORE                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         INPUT PROCESSING                               â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚ â”‚
â”‚  â”‚  â”‚   Token     â”‚    â”‚  Position   â”‚    â”‚   Modal     â”‚               â”‚ â”‚
â”‚  â”‚  â”‚  Embedding  â”‚ +  â”‚  Encoding   â”‚ +  â”‚  Encoding   â”‚ = Input Embed â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    SELECTIVE STATE SPACE BACKBONE                      â”‚ â”‚
â”‚  â”‚                                                                        â”‚ â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”                   â”‚ â”‚
â”‚  â”‚    â”‚ SSS â”‚ -> â”‚ SSS â”‚ -> â”‚ SSS â”‚ -> ... -> â”‚ SSS â”‚                   â”‚ â”‚
â”‚  â”‚    â”‚  1  â”‚    â”‚  2  â”‚    â”‚  3  â”‚           â”‚  L  â”‚                   â”‚ â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”˜                   â”‚ â”‚
â”‚  â”‚                     O(n) Linear Complexity                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                        â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                    â”‚               â”‚               â”‚                       â”‚
â”‚                    â–¼               â–¼               â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   WORLD MODEL    â”‚ â”‚    REASONER      â”‚ â”‚  CAUSAL ENGINE   â”‚           â”‚
â”‚  â”‚                  â”‚ â”‚                  â”‚ â”‚                  â”‚           â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚           â”‚
â”‚  â”‚ â”‚   Context    â”‚ â”‚ â”‚ â”‚    Rule      â”‚ â”‚ â”‚ â”‚     SCM      â”‚ â”‚           â”‚
â”‚  â”‚ â”‚   Encoder    â”‚ â”‚ â”‚ â”‚    Base      â”‚ â”‚ â”‚ â”‚   Learner    â”‚ â”‚           â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚           â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚           â”‚
â”‚  â”‚ â”‚   Target     â”‚ â”‚ â”‚ â”‚    Soft      â”‚ â”‚ â”‚ â”‚   Causal     â”‚ â”‚           â”‚
â”‚  â”‚ â”‚   Encoder    â”‚ â”‚ â”‚ â”‚ Unification  â”‚ â”‚ â”‚ â”‚  Attention   â”‚ â”‚           â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚           â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚           â”‚
â”‚  â”‚ â”‚  Predictor   â”‚ â”‚ â”‚ â”‚   Proof      â”‚ â”‚ â”‚ â”‚ Counterfact  â”‚ â”‚           â”‚
â”‚  â”‚ â”‚              â”‚ â”‚ â”‚ â”‚   Tracer     â”‚ â”‚ â”‚ â”‚   Reasoner   â”‚ â”‚           â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚           â”‚
â”‚  â”‚                  â”‚ â”‚                  â”‚ â”‚                  â”‚           â”‚
â”‚  â”‚  JEPA-Style     â”‚ â”‚  Neuro-Symbolic  â”‚ â”‚    Causal       â”‚           â”‚
â”‚  â”‚  Prediction     â”‚ â”‚    Reasoning     â”‚ â”‚   Inference     â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                    â”‚               â”‚               â”‚                       â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                       ENERGY-BASED REFINEMENT                          â”‚ â”‚
â”‚  â”‚                                                                        â”‚ â”‚
â”‚  â”‚    Input â”€â”€â–º Energy Function â”€â”€â–º Gradient â”€â”€â–º Refined Output          â”‚ â”‚
â”‚  â”‚              E(x, y)           âˆ‡E           (iterate until converge)  â”‚ â”‚
â”‚  â”‚                                                                        â”‚ â”‚
â”‚  â”‚    Adaptive computation: more iterations for harder inputs            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                         OUTPUT GENERATION                              â”‚ â”‚
â”‚  â”‚                                                                        â”‚ â”‚
â”‚  â”‚    Refined Repr â”€â”€â–º Output Projection â”€â”€â–º Softmax â”€â”€â–º Logits          â”‚ â”‚
â”‚  â”‚                                                                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Interactions

### Information Flow Diagram

```
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚     Input       â”‚
                              â”‚   (tokens)      â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚   Embedding     â”‚
                              â”‚     Layer       â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  State Space    â”‚
                              â”‚    Backbone     â”‚â—„â”€â”€â”€â”€ O(n) processing
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                  â”‚                  â”‚
                    â–¼                  â–¼                  â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚   World     â”‚    â”‚  Reasoner   â”‚    â”‚   Causal    â”‚
             â”‚   Model     â”‚    â”‚             â”‚    â”‚   Engine    â”‚
             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                  â”‚                  â”‚
                    â”‚    Predictions   â”‚   Proofs        â”‚  Causal
                    â”‚                  â”‚                  â”‚  Structure
                    â”‚                  â”‚                  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚    Fusion       â”‚
                              â”‚    Module       â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚    Energy       â”‚â—„â”€â”€â”€â”€ Adaptive depth
                              â”‚   Refinement    â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚    Output       â”‚
                              â”‚   Projection    â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚    Logits       â”‚
                              â”‚   (vocab_size)  â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Detailed Component Specifications

### 1. Input Processing

| Component | Input | Output | Purpose |
|-----------|-------|--------|---------|
| Token Embedding | `[B, L]` indices | `[B, L, D]` | Map tokens to vectors |
| Position Encoding | `[L]` positions | `[L, D]` | Add position information |
| Modal Encoding | Modal type | `[D]` | Distinguish modalities |

**Configuration**:
```python
embedding_config = {
    'vocab_size': 32000,
    'd_model': 512,        # Hidden dimension
    'max_seq_len': 8192,   # Maximum sequence length
    'dropout': 0.1,
}
```

### 2. State Space Backbone

| Parameter | Typical Value | Description |
|-----------|---------------|-------------|
| d_model | 512-2048 | Model width |
| ssm_d_state | 64-256 | State space dimension |
| n_heads | 8-32 | Attention heads (world model) |
| ssm_n_layers | 6-24 | Depth |

**Layer Structure**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     State Space Layer            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input Norm â”€â”€â–º Selective SSM     â”‚
â”‚              â”€â”€â–º Output Project  â”‚
â”‚              â”€â”€â–º Residual Add    â”‚
â”‚              â”€â”€â–º FFN             â”‚
â”‚              â”€â”€â–º Residual Add    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Auxiliary Modules

**World Model**:
```
Context Encoder: Transformer layers (4-8)
Target Encoder: EMA copy of context encoder
Predictor: MLP (2-4 layers)
Temporal Abstraction: Pooling at multiple scales
```

**Reasoner**:
```
Rule Base: Learnable embeddings (50-500 rules)
Unification: Attention-based soft matching
Proof Tracer: Stack-based derivation recording
Knowledge Graph: Optional external grounding
```

**Causal Engine**:
```
SCM Learner: Differentiable DAG learning
Causal Attention: Masked attention following DAG
Counterfactual: Abduction-action-prediction pipeline
```

### 4. Energy Module

```
Energy Function: MLP mapping (x, y) â†’ scalar
Refinement: Gradient descent on y
Convergence: Energy threshold or iteration limit
Output: Refined representation + energy history
```

---

## Memory and Compute Profiles

### Memory Usage (Approximate)

| Component | Memory | Notes |
|-----------|--------|-------|
| Embeddings | O(V Ã— D) | V=vocab, D=dim |
| State Space | O(L Ã— D) | L=length, per layer |
| World Model | O(L Ã— D) | Encoder representations |
| Reasoner | O(R Ã— D) | R=rules |
| Causal | O(VÂ² + L Ã— D) | V=variables |
| Energy | O(L Ã— D) | Refinement states |

**Total**: O(L Ã— D Ã— Layers) â‰ˆ **Linear in sequence length**

### Compute Profile (FLOPs)

| Component | FLOPs | Complexity |
|-----------|-------|------------|
| State Space | 6 Ã— L Ã— DÂ² | O(n) |
| World Model | 4 Ã— L Ã— DÂ² | O(n) |
| Reasoner | R Ã— L Ã— D | O(n) |
| Causal | VÂ² Ã— D + L Ã— DÂ² | O(n + VÂ²) |
| Energy | I Ã— L Ã— DÂ² | O(n Ã— I) |

Where I = refinement iterations (typically 1-10)

---

## Configuration Hierarchy

```yaml
nexus_config:
  # Core dimensions (NEXUSConfig dataclass parameters)
  vocab_size: 32000
  d_model: 512            # Hidden dimension
  d_latent: 256           # Latent dimension for world model
  ssm_n_layers: 12        # Number of state space layers
  n_heads: 8              # Attention heads
  ssm_d_state: 64         # State space state dimension
  ssm_d_conv: 4           # Convolution kernel size
  ssm_expand: 2           # Expansion factor
  
  # Reasoning
  n_predicates: 64        # Number of reasoning predicates
  n_constants: 128        # Number of reasoning constants
  max_reasoning_steps: 5  # Maximum reasoning iterations
  
  # Causal
  n_variables: 32         # Number of causal variables
  
  # Energy
  max_energy_iters: 10    # Maximum energy iterations
  
  # Sequence
  max_seq_len: 8192       # Maximum sequence length
  dropout: 0.1            # Dropout rate
```

---

## Scaling Properties

### Model Size Configurations

| Config | ssm_n_layers | d_model | n_heads | Params |
|--------|--------------|---------|---------|--------|
| Tiny | 4 | 256 | 4 | ~10M |
| Small | 6 | 512 | 8 | ~50M |
| Medium | 12 | 1024 | 16 | ~200M |
| Large | 24 | 2048 | 32 | ~800M |
| XL | 32 | 4096 | 64 | ~3B |

### Scaling Laws

Based on empirical observations:

**Compute-Optimal Training**:
```
Optimal tokens â‰ˆ 20 Ã— Parameters
(Similar to Chinchilla scaling)
```

**Loss Scaling**:
```
L(N, D) = A/N^Î± + B/D^Î² + C
Where N = params, D = data
Î± â‰ˆ 0.5, Î² â‰ˆ 0.5
```

---

## Deployment Modes

### 1. Full NEXUS (All Components)
- Maximum capability
- Highest compute
- Use for: Research, complex reasoning

### 2. Fast NEXUS (State Space + Energy)
- High efficiency
- Skip world model and reasoner
- Use for: Production inference

### 3. Reasoning NEXUS (State Space + Reasoner)
- Focused on explainability
- Include proof traces
- Use for: Verified reasoning tasks

### 4. Causal NEXUS (State Space + Causal)
- Focused on interventions
- Include causal discovery
- Use for: Decision-making, planning

---

## Extension Points

NEXUS is designed for extensibility:

```python
class NEXUSCore:
    def register_module(self, name: str, module: nn.Module):
        """Add custom auxiliary module."""
        
    def register_loss(self, name: str, loss_fn: Callable):
        """Add custom loss term."""
        
    def register_callback(self, event: str, callback: Callable):
        """Add training callbacks."""
```

**Example Extensions**:
- Retrieval-Augmented Generation
- Multi-modal encoders
- Custom reasoning engines
- Domain-specific losses

---

## Further Reading

### Core Architecture
- [State Space Details](state-space.md)
- [World Model Details](world-model.md)
- [Reasoning Details](reasoning.md)
- [Energy Module Details](energy.md)
- [Causal Engine Details](causal.md)
- [Integration Layer](integration.md)

### Production Infrastructure (v2.0)
- [Production Architecture](production.md) - Complete production infrastructure guide
- [Deployment Guide](../deployment/deployment-guide.md)
- [Operations Runbook](../operations/runbook.md)

---

*Architecture is frozen music. NEXUS orchestrates computation.*
